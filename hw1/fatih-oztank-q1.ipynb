{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/fatih/Documents/dersler/cs528/hw1/fatih-oztank-q1.ipynb Cell 1'\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/fatih/Documents/dersler/cs528/hw1/fatih-oztank-q1.ipynb#ch0000000?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/fatih/Documents/dersler/cs528/hw1/fatih-oztank-q1.ipynb#ch0000000?line=2'>3</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mgeopy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdistance\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/fatih/Documents/dersler/cs528/hw1/fatih-oztank-q1.ipynb#ch0000000?line=3'>4</a>\u001b[0m sc \u001b[39m=\u001b[39m SparkContext\u001b[39m.\u001b[39;49mgetOrCreate()\n",
      "File \u001b[0;32m~/Documents/dersler/cs528/cs528venv/lib/python3.9/site-packages/pyspark/context.py:392\u001b[0m, in \u001b[0;36mSparkContext.getOrCreate\u001b[0;34m(cls, conf)\u001b[0m\n\u001b[1;32m    <a href='file:///home/fatih/Documents/dersler/cs528/cs528venv/lib/python3.9/site-packages/pyspark/context.py?line=389'>390</a>\u001b[0m \u001b[39mwith\u001b[39;00m SparkContext\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    <a href='file:///home/fatih/Documents/dersler/cs528/cs528venv/lib/python3.9/site-packages/pyspark/context.py?line=390'>391</a>\u001b[0m     \u001b[39mif\u001b[39;00m SparkContext\u001b[39m.\u001b[39m_active_spark_context \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///home/fatih/Documents/dersler/cs528/cs528venv/lib/python3.9/site-packages/pyspark/context.py?line=391'>392</a>\u001b[0m         SparkContext(conf\u001b[39m=\u001b[39;49mconf \u001b[39mor\u001b[39;49;00m SparkConf())\n\u001b[1;32m    <a href='file:///home/fatih/Documents/dersler/cs528/cs528venv/lib/python3.9/site-packages/pyspark/context.py?line=392'>393</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m SparkContext\u001b[39m.\u001b[39m_active_spark_context\n",
      "File \u001b[0;32m~/Documents/dersler/cs528/cs528venv/lib/python3.9/site-packages/pyspark/context.py:144\u001b[0m, in \u001b[0;36mSparkContext.__init__\u001b[0;34m(self, master, appName, sparkHome, pyFiles, environment, batchSize, serializer, conf, gateway, jsc, profiler_cls)\u001b[0m\n\u001b[1;32m    <a href='file:///home/fatih/Documents/dersler/cs528/cs528venv/lib/python3.9/site-packages/pyspark/context.py?line=138'>139</a>\u001b[0m \u001b[39mif\u001b[39;00m gateway \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m gateway\u001b[39m.\u001b[39mgateway_parameters\u001b[39m.\u001b[39mauth_token \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    <a href='file:///home/fatih/Documents/dersler/cs528/cs528venv/lib/python3.9/site-packages/pyspark/context.py?line=139'>140</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    <a href='file:///home/fatih/Documents/dersler/cs528/cs528venv/lib/python3.9/site-packages/pyspark/context.py?line=140'>141</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mYou are trying to pass an insecure Py4j gateway to Spark. This\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///home/fatih/Documents/dersler/cs528/cs528venv/lib/python3.9/site-packages/pyspark/context.py?line=141'>142</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m is not allowed as it is a security risk.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> <a href='file:///home/fatih/Documents/dersler/cs528/cs528venv/lib/python3.9/site-packages/pyspark/context.py?line=143'>144</a>\u001b[0m SparkContext\u001b[39m.\u001b[39;49m_ensure_initialized(\u001b[39mself\u001b[39;49m, gateway\u001b[39m=\u001b[39;49mgateway, conf\u001b[39m=\u001b[39;49mconf)\n\u001b[1;32m    <a href='file:///home/fatih/Documents/dersler/cs528/cs528venv/lib/python3.9/site-packages/pyspark/context.py?line=144'>145</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    <a href='file:///home/fatih/Documents/dersler/cs528/cs528venv/lib/python3.9/site-packages/pyspark/context.py?line=145'>146</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,\n\u001b[1;32m    <a href='file:///home/fatih/Documents/dersler/cs528/cs528venv/lib/python3.9/site-packages/pyspark/context.py?line=146'>147</a>\u001b[0m                   conf, jsc, profiler_cls)\n",
      "File \u001b[0;32m~/Documents/dersler/cs528/cs528venv/lib/python3.9/site-packages/pyspark/context.py:339\u001b[0m, in \u001b[0;36mSparkContext._ensure_initialized\u001b[0;34m(cls, instance, gateway, conf)\u001b[0m\n\u001b[1;32m    <a href='file:///home/fatih/Documents/dersler/cs528/cs528venv/lib/python3.9/site-packages/pyspark/context.py?line=336'>337</a>\u001b[0m \u001b[39mwith\u001b[39;00m SparkContext\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    <a href='file:///home/fatih/Documents/dersler/cs528/cs528venv/lib/python3.9/site-packages/pyspark/context.py?line=337'>338</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m SparkContext\u001b[39m.\u001b[39m_gateway:\n\u001b[0;32m--> <a href='file:///home/fatih/Documents/dersler/cs528/cs528venv/lib/python3.9/site-packages/pyspark/context.py?line=338'>339</a>\u001b[0m         SparkContext\u001b[39m.\u001b[39m_gateway \u001b[39m=\u001b[39m gateway \u001b[39mor\u001b[39;00m launch_gateway(conf)\n\u001b[1;32m    <a href='file:///home/fatih/Documents/dersler/cs528/cs528venv/lib/python3.9/site-packages/pyspark/context.py?line=339'>340</a>\u001b[0m         SparkContext\u001b[39m.\u001b[39m_jvm \u001b[39m=\u001b[39m SparkContext\u001b[39m.\u001b[39m_gateway\u001b[39m.\u001b[39mjvm\n\u001b[1;32m    <a href='file:///home/fatih/Documents/dersler/cs528/cs528venv/lib/python3.9/site-packages/pyspark/context.py?line=341'>342</a>\u001b[0m     \u001b[39mif\u001b[39;00m instance:\n",
      "File \u001b[0;32m~/Documents/dersler/cs528/cs528venv/lib/python3.9/site-packages/pyspark/java_gateway.py:105\u001b[0m, in \u001b[0;36mlaunch_gateway\u001b[0;34m(conf, popen_kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///home/fatih/Documents/dersler/cs528/cs528venv/lib/python3.9/site-packages/pyspark/java_gateway.py?line=102'>103</a>\u001b[0m \u001b[39m# Wait for the file to appear, or for the process to exit, whichever happens first.\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/fatih/Documents/dersler/cs528/cs528venv/lib/python3.9/site-packages/pyspark/java_gateway.py?line=103'>104</a>\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mnot\u001b[39;00m proc\u001b[39m.\u001b[39mpoll() \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39misfile(conn_info_file):\n\u001b[0;32m--> <a href='file:///home/fatih/Documents/dersler/cs528/cs528venv/lib/python3.9/site-packages/pyspark/java_gateway.py?line=104'>105</a>\u001b[0m     time\u001b[39m.\u001b[39;49msleep(\u001b[39m0.1\u001b[39;49m)\n\u001b[1;32m    <a href='file:///home/fatih/Documents/dersler/cs528/cs528venv/lib/python3.9/site-packages/pyspark/java_gateway.py?line=106'>107</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39misfile(conn_info_file):\n\u001b[1;32m    <a href='file:///home/fatih/Documents/dersler/cs528/cs528venv/lib/python3.9/site-packages/pyspark/java_gateway.py?line=107'>108</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mJava gateway process exited before sending its port number\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from pyspark import SparkContext\n",
    "import numpy as np\n",
    "import geopy.distance\n",
    "sc = SparkContext.getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitAndTake(line):\n",
    "    arr = line.split('\\t')\n",
    "    country = str(arr[1])\n",
    "    capital = str(arr[2])\n",
    "    lat = float(arr[3].strip().replace(\",\",\".\"))\n",
    "    lon = float(arr[4].strip().replace(\",\",\".\"))\n",
    "    return(country, capital, lat, lon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "capital_rdd = sc.textFile(\"datasets/Capitals.txt\")\n",
    "capital_rdd = capital_rdd.map(lambda line: splitAndTake(line))\n",
    "capital_rdd = capital_rdd.filter(lambda x: x[2] >= -90)\n",
    "capital_rdd = capital_rdd.filter(lambda x: x[2] <= 90)\n",
    "capital_rdd = capital_rdd.sortBy(lambda x: x[2],ascending=True) # dropping some capitals due to latitude problems\n",
    "#capital_rdd.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findDistanceBetweenCapitals(line):\n",
    "    f_coord = (line[0][2], line[0][3])\n",
    "    s_coord = (line[1][2], line[1][3])\n",
    "    f_capital = line[0][1]\n",
    "    s_capital = line[1][1]\n",
    "    dist = geopy.distance.geodesic(f_coord,s_coord).km\n",
    "    return (f_capital, s_capital, dist)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Jerusalem ', 'East Jerusalem ', 0.0),\n",
       " ('East Jerusalem ', 'Jerusalem ', 0.0),\n",
       " ('Rome ', 'Vatican ', 2.72613532590367),\n",
       " ('Vatican ', 'Rome ', 2.72613532590367),\n",
       " ('Kinshasa ', 'Brazzaville ', 6.454518401229527),\n",
       " ('Brazzaville ', 'Kinshasa ', 6.454518401229527),\n",
       " ('Marigot ', 'The Valley ', 16.73665420507278),\n",
       " ('The Valley ', 'Marigot ', 16.73665420507278),\n",
       " ('Gustavia ', 'Marigot ', 30.78062900685881),\n",
       " ('Marigot ', 'Gustavia ', 30.78062900685881)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "country_pairs = capital_rdd.cartesian(capital_rdd)\n",
    "country_pairs = country_pairs.filter(lambda x: x[0] != x[1])\n",
    "capitals = country_pairs.map(lambda line: findDistanceBetweenCapitals(line))\n",
    "capitals = capitals.sortBy(lambda line: line[2], ascending=True)\n",
    "capitals.take(10)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6389c4f3611612d81a5ee170de9679905eb10b2a5a31904a2f8d152d44906565"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 ('cs528venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
